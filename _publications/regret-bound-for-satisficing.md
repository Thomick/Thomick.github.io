---
title: "Regret Bounds for Satisficing in Multi-Armed Bandit Problems"
collection: publications
permalink: /publication/regret-bound-for-satisficing
excerpt: 'This paper considers the objective of satisficing in multi-armed bandit problems. Instead of aiming to find an optimal arm, the learner is content with an arm whose reward is above a given satisfaction level.'
date: 2023-06-09
venue: 'Transactions on Machine Learning Research'
paperurl: 'http://thomick.github.io/files/regret-bound-for-satisficing.pdf'
citation: 'Michel, T., Hajiabolhassan, H., & Ortner, R. (2023). &quot;Regret Bounds for Satisficing in Multi-Armed Bandit Problems.&quot; <i>Transactions on Machine Learning Research</i>.'
---
This paper considers the objective of satisficing in multi-armed bandit problems. Instead of aiming to find an optimal arm, the learner is content with an arm whose reward is above a given satisfaction level. We provide algorithms and analysis for the realizable case when such a satisficing arm exists as well as for the general case when this may not be the case. Introducing the notion of satisficing regret, our main result shows that in the general case it is possible to obtain constant satisficing regret when there is a satisficing arm (thereby correcting a contrary claim in the literature), while standard logarithmic regret bounds can be re-established otherwise. Experiments illustrate that our algorithm is not only superior to standard algorithms in the satisficing setting, but also works well in the classic bandit setting.

[Download paper here](http://thomick.github.io/files/regret-bound-for-satisficing.pdf)
